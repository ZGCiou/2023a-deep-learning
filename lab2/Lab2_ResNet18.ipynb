{"cells":[{"cell_type":"markdown","source":["# Lab2 ResNest18\n"],"metadata":{"id":"GIa8r4Qr-nON"}},{"cell_type":"markdown","source":["## Google Colab"],"metadata":{"id":"-vsUb-x_-utQ"}},{"cell_type":"code","source":["# Connect to google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Change working path\n","import os\n","path = \"/content/drive/MyDrive/Colab Notebooks/DeepLearning/Lab02\"\n","os.chdir(path)\n","print(os.getcwd())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WP1cCCto-2Fj","executionInfo":{"status":"ok","timestamp":1698576261549,"user_tz":-480,"elapsed":2488,"user":{"displayName":"邱政岡","userId":"04098387973150804913"}},"outputId":"4abfc23f-4945-4696-84b3-52f636252de6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Colab Notebooks/DeepLearning/Lab02\n"]}]},{"cell_type":"markdown","source":["## Import Package"],"metadata":{"id":"8l2yddJE_g2t"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"ngfZew4R73Cx","executionInfo":{"status":"ok","timestamp":1698576261549,"user_tz":-480,"elapsed":9,"user":{"displayName":"邱政岡","userId":"04098387973150804913"}}},"outputs":[],"source":["# Numerical Operations\n","import numpy as np\n","\n","# Pytorch\n","import torch\n","import torch.nn as nn             # Neural Network Modual\n","import torch.nn.functional as F   # Activation Function\n","import torch.optim as optim       # Optimizer\n","import torch.utils.data as data   # Batch training\n","import torchvision\n","import torchvision.utils as utils\n","from torchvision import datasets, transforms, models\n","\n","# Poltting\n","import matplotlib.pyplot as plt\n","\n","import os"]},{"cell_type":"markdown","source":["## Dataset"],"metadata":{"id":"fswxJ2WNDMig"}},{"cell_type":"code","execution_count":10,"metadata":{"id":"FS2W7MXg73C0","executionInfo":{"status":"ok","timestamp":1698576261550,"user_tz":-480,"elapsed":9,"user":{"displayName":"邱政岡","userId":"04098387973150804913"}}},"outputs":[],"source":["# dataset path\n","data_path_train = \"./data/training\"\n","data_path_test = \"./data/testing\""]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0-JhcMAL73C0","executionInfo":{"status":"ok","timestamp":1698576261550,"user_tz":-480,"elapsed":9,"user":{"displayName":"邱政岡","userId":"04098387973150804913"}},"outputId":"3bead59a-8d80-4ce6-c9da-1626edbaee35"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset ImageFolder\n","    Number of datapoints: 1646\n","    Root location: ./data/training\n","    StandardTransform\n","Transform: Compose(\n","               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n","               ToTensor()\n","           )\n","{'Baked Potato': 0, 'Crispy Chicken': 1, 'Donut': 2, 'Fries': 3}\n"]}],"source":["# data transform, you can add different transform methods and resize image to any size\n","img_size = 224\n","transform = transforms.Compose([\n","                       transforms.Resize((img_size,img_size)),\n","                       transforms.ToTensor()\n","                       ])\n","\n","# build dataset\n","dataset = datasets.ImageFolder(root=data_path_train,transform=transform)\n","\n","# spilt your data into train and val\n","TOTAL_SIZE = len(dataset)\n","ratio = 0.9\n","train_len = round(TOTAL_SIZE * ratio)\n","valid_len = round(TOTAL_SIZE * (1-ratio))\n","train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_len, valid_len])\n","\n","#build dataloader\n","train_data_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True,  num_workers=4)\n","val_data_loader = data.DataLoader(val_dataset, batch_size=32, shuffle=True,  num_workers=4)\n","\n","#check dataset\n","print(dataset)\n","print(dataset.class_to_idx)"]},{"cell_type":"markdown","source":["## Train Function"],"metadata":{"id":"EDtujo06bg6g"}},{"cell_type":"code","execution_count":12,"metadata":{"id":"etoyTsSt73C1","executionInfo":{"status":"ok","timestamp":1698576261550,"user_tz":-480,"elapsed":7,"user":{"displayName":"邱政岡","userId":"04098387973150804913"}}},"outputs":[],"source":["#train function\n","def train(model, criterion, optimizer):\n","    model.train()\n","    total_loss = 0.0\n","    total_correct = 0\n","\n","    # Iterate over data\n","    for inputs, labels in train_data_loader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        loss = criterion(outputs, labels)\n","\n","        # backward + optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        # statistics\n","        total_loss += loss.item()\n","        total_correct += torch.sum(preds == labels.data)\n","\n","    avg_loss = total_loss / len(train_data_loader)\n","    accuracy = total_correct.double() / len(train_dataset) * 100\n","\n","    print('Training Accuracy: {:.4f}% Training Loss: {:.4f}'.format(accuracy, avg_loss))\n","    return\n","\n","#validation function\n","def valid(model, criterion, scheduler):\n","    model.eval()\n","    total_loss = 0.0\n","    total_correct = 0\n","\n","    # Iterate over data\n","    for inputs, labels in val_data_loader:\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","\n","        # forward\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs, 1)\n","        loss = criterion(outputs, labels)\n","\n","        # statistics\n","        total_loss += loss.item()\n","        total_correct += torch.sum(preds == labels.data)\n","\n","    avg_loss = total_loss / len(val_data_loader)\n","    accuracy = total_correct.double() / len(val_dataset) * 100\n","    scheduler.step(avg_loss)\n","\n","    print('Validation Accuracy: {:.4f}% Validation Loss: {:.4f}'.format(accuracy, avg_loss))\n","    return accuracy"]},{"cell_type":"markdown","source":["## Network Model"],"metadata":{"id":"1940mndTbl0P"}},{"cell_type":"code","execution_count":13,"metadata":{"id":"Jb3K93Hk73C1","executionInfo":{"status":"ok","timestamp":1698576261550,"user_tz":-480,"elapsed":7,"user":{"displayName":"邱政岡","userId":"04098387973150804913"}}},"outputs":[],"source":["from torch.nn.modules.activation import ReLU\n","from torch.ao.nn.quantized.modules import BatchNorm2d\n","# using gpu if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# build your model here\n","class ResBlock(nn.Module):\n","    def __init__(self, in_features, out_features):\n","        super(ResBlock, self).__init__()\n","        self.cross = (in_features != out_features)\n","        stride = 2 if self.cross else 1\n","        self.hidden1 = nn.Sequential(\n","            nn.Conv2d(in_features, out_features, 3, stride, 1),     # Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n","            nn.BatchNorm2d(out_features)\n","        )\n","        self.hidden2 = nn.Sequential(\n","            nn.Conv2d(out_features, out_features, 3, 1, 1),\n","            nn.BatchNorm2d(out_features)\n","        )\n","        self.downsample = nn.Conv2d(in_features, out_features, 1, 2)   # 1x1 convoultion\n","\n","    def forward(self, x):\n","        '''Shortcut path'''\n","        if (self.cross):\n","            res = self.downsample(x)\n","        else:\n","            res = x\n","\n","        out = F.relu(self.hidden1(x))\n","        out = self.hidden2(out)\n","        out = F.relu(out + res)\n","        return out\n","\n","class RN18(nn.Module):\n","    def __init__(self):\n","        super(RN18, self).__init__()\n","        self.conv1 = nn.Conv2d(\n","            in_channels=3,\n","            out_channels=64,\n","            kernel_size=7,\n","            stride=2,\n","            padding=5\n","        )\n","        self.conv2_x = nn.Sequential(\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","            ResBlock(64, 64),\n","            ResBlock(64, 64)\n","        )\n","        self.conv3_x = nn.Sequential(\n","            ResBlock(64, 128),\n","            ResBlock(128, 128)\n","        )\n","        self.conv4_x = nn.Sequential(\n","            ResBlock(128, 256),\n","            ResBlock(256, 256)\n","        )\n","        self.conv5_x = nn.Sequential(\n","            ResBlock(256, 512),\n","            ResBlock(512, 512),\n","            nn.AdaptiveAvgPool2d(1)\n","        )\n","        self.out = nn.Linear(512, 1000)\n","\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2_x(x)\n","        x = self.conv3_x(x)\n","        x = self.conv4_x(x)\n","        x = self.conv5_x(x)\n","        x = torch.flatten(x, start_dim=1)\n","        x = self.out(x)\n","        return x\n","\n","#call model\n","model = RN18()\n","# print(model)"]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"e9Sm3kpLb71W"}},{"cell_type":"code","execution_count":14,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"GRKZIhQo73C2","executionInfo":{"status":"ok","timestamp":1698577844397,"user_tz":-480,"elapsed":1582853,"user":{"displayName":"邱政岡","userId":"04098387973150804913"}},"outputId":"c88eeb7c-c7b7-4722-b406-6ad085272700"},"outputs":[{"output_type":"stream","name":"stdout","text":["--------------start training--------------\n","epoch: 1\n","Training Accuracy: 52.1269% Training Loss: 2.7338\n","Validation Accuracy: 49.0909% Validation Loss: 2.0558\n","model saved\n","epoch: 2\n","Training Accuracy: 68.6023% Training Loss: 0.8679\n","Validation Accuracy: 48.4848% Validation Loss: 1.3676\n","epoch: 3\n","Training Accuracy: 70.0203% Training Loss: 0.7787\n","Validation Accuracy: 61.2121% Validation Loss: 1.1784\n","model saved\n","epoch: 4\n","Training Accuracy: 75.7596% Training Loss: 0.6465\n","Validation Accuracy: 66.0606% Validation Loss: 1.0408\n","model saved\n","epoch: 5\n","Training Accuracy: 76.5699% Training Loss: 0.6180\n","Validation Accuracy: 62.4242% Validation Loss: 1.2145\n","epoch: 6\n","Training Accuracy: 81.4990% Training Loss: 0.5157\n","Validation Accuracy: 67.8788% Validation Loss: 0.9432\n","model saved\n","epoch: 7\n","Training Accuracy: 80.8238% Training Loss: 0.5238\n","Validation Accuracy: 67.8788% Validation Loss: 0.9249\n","epoch: 8\n","Training Accuracy: 85.9554% Training Loss: 0.4019\n","Validation Accuracy: 71.5152% Validation Loss: 0.7097\n","model saved\n","epoch: 9\n","Training Accuracy: 88.3862% Training Loss: 0.3211\n","Validation Accuracy: 60.0000% Validation Loss: 1.4319\n","epoch: 10\n","Training Accuracy: 89.8717% Training Loss: 0.3236\n","Validation Accuracy: 50.3030% Validation Loss: 2.3696\n","epoch: 11\n","Training Accuracy: 92.4375% Training Loss: 0.2179\n","Validation Accuracy: 69.6970% Validation Loss: 0.9695\n","epoch: 12\n","Training Accuracy: 94.3282% Training Loss: 0.1543\n","Validation Accuracy: 72.7273% Validation Loss: 0.7529\n","model saved\n","epoch: 13\n","Training Accuracy: 95.4085% Training Loss: 0.1434\n","Validation Accuracy: 69.6970% Validation Loss: 1.1111\n","epoch: 14\n","Training Accuracy: 95.2059% Training Loss: 0.1407\n","Validation Accuracy: 67.2727% Validation Loss: 1.1988\n","epoch: 15\n","Training Accuracy: 93.1803% Training Loss: 0.2007\n","Validation Accuracy: 74.5455% Validation Loss: 0.7998\n","model saved\n","epoch: 16\n","Training Accuracy: 96.7589% Training Loss: 0.0959\n","Validation Accuracy: 75.1515% Validation Loss: 0.8661\n","model saved\n","epoch: 17\n","Training Accuracy: 98.5820% Training Loss: 0.0601\n","Validation Accuracy: 79.3939% Validation Loss: 0.6578\n","model saved\n","epoch: 18\n","Training Accuracy: 95.5436% Training Loss: 0.1501\n","Validation Accuracy: 67.8788% Validation Loss: 1.5141\n","epoch: 19\n","Training Accuracy: 93.7205% Training Loss: 0.1878\n","Validation Accuracy: 69.0909% Validation Loss: 0.9306\n","epoch: 20\n","Training Accuracy: 96.9615% Training Loss: 0.0895\n","Validation Accuracy: 78.1818% Validation Loss: 1.0266\n","epoch: 21\n","Training Accuracy: 98.5820% Training Loss: 0.0449\n","Validation Accuracy: 78.1818% Validation Loss: 0.6535\n","epoch: 22\n","Training Accuracy: 99.3248% Training Loss: 0.0269\n","Validation Accuracy: 74.5455% Validation Loss: 0.7592\n","epoch: 23\n","Training Accuracy: 99.2573% Training Loss: 0.0253\n","Validation Accuracy: 78.7879% Validation Loss: 0.8547\n","epoch: 24\n","Training Accuracy: 99.5949% Training Loss: 0.0168\n","Validation Accuracy: 75.7576% Validation Loss: 0.9119\n","epoch: 25\n","Training Accuracy: 99.7299% Training Loss: 0.0152\n","Validation Accuracy: 78.1818% Validation Loss: 0.9649\n","epoch: 26\n","Training Accuracy: 99.8650% Training Loss: 0.0095\n","Validation Accuracy: 76.3636% Validation Loss: 0.8230\n","epoch: 27\n","Training Accuracy: 99.7974% Training Loss: 0.0093\n","Validation Accuracy: 77.5758% Validation Loss: 0.7562\n","epoch: 28\n","Training Accuracy: 99.9325% Training Loss: 0.0049\n","Validation Accuracy: 78.7879% Validation Loss: 0.9471\n","epoch: 29\n","Training Accuracy: 99.7974% Training Loss: 0.0110\n","Validation Accuracy: 76.3636% Validation Loss: 1.0333\n","epoch: 30\n","Training Accuracy: 96.8940% Training Loss: 0.0933\n","Validation Accuracy: 58.7879% Validation Loss: 1.7812\n","epoch: 31\n","Training Accuracy: 97.7043% Training Loss: 0.0895\n","Validation Accuracy: 68.4848% Validation Loss: 1.4835\n","epoch: 32\n","Training Accuracy: 94.7333% Training Loss: 0.1393\n","Validation Accuracy: 64.8485% Validation Loss: 1.8726\n","epoch: 33\n","Training Accuracy: 98.7846% Training Loss: 0.0420\n","Validation Accuracy: 74.5455% Validation Loss: 0.9911\n","epoch: 34\n","Training Accuracy: 99.7299% Training Loss: 0.0170\n","Validation Accuracy: 75.1515% Validation Loss: 0.7285\n","epoch: 35\n","Training Accuracy: 99.8650% Training Loss: 0.0133\n","Validation Accuracy: 75.7576% Validation Loss: 0.9620\n","epoch: 36\n","Training Accuracy: 99.7299% Training Loss: 0.0118\n","Validation Accuracy: 74.5455% Validation Loss: 1.0990\n","epoch: 37\n","Training Accuracy: 99.8650% Training Loss: 0.0121\n","Validation Accuracy: 75.7576% Validation Loss: 0.7088\n","epoch: 38\n","Training Accuracy: 99.7299% Training Loss: 0.0134\n","Validation Accuracy: 76.3636% Validation Loss: 0.7825\n","epoch: 39\n","Training Accuracy: 99.8650% Training Loss: 0.0073\n","Validation Accuracy: 77.5758% Validation Loss: 0.7498\n","epoch: 40\n","Training Accuracy: 99.9325% Training Loss: 0.0087\n","Validation Accuracy: 75.1515% Validation Loss: 0.9151\n","epoch: 41\n","Training Accuracy: 100.0000% Training Loss: 0.0063\n","Validation Accuracy: 76.9697% Validation Loss: 0.8040\n","epoch: 42\n","Training Accuracy: 99.9325% Training Loss: 0.0063\n","Validation Accuracy: 76.3636% Validation Loss: 0.7338\n","epoch: 43\n","Training Accuracy: 99.8650% Training Loss: 0.0085\n","Validation Accuracy: 77.5758% Validation Loss: 1.1987\n","epoch: 44\n","Training Accuracy: 99.9325% Training Loss: 0.0061\n","Validation Accuracy: 76.9697% Validation Loss: 0.7767\n","epoch: 45\n","Training Accuracy: 100.0000% Training Loss: 0.0050\n","Validation Accuracy: 76.9697% Validation Loss: 0.8802\n","epoch: 46\n","Training Accuracy: 100.0000% Training Loss: 0.0035\n","Validation Accuracy: 76.9697% Validation Loss: 0.7444\n","epoch: 47\n","Training Accuracy: 99.7974% Training Loss: 0.0088\n","Validation Accuracy: 76.9697% Validation Loss: 0.9172\n","epoch: 48\n","Training Accuracy: 99.9325% Training Loss: 0.0063\n","Validation Accuracy: 78.7879% Validation Loss: 0.8935\n","epoch: 49\n","Training Accuracy: 99.7974% Training Loss: 0.0068\n","Validation Accuracy: 76.3636% Validation Loss: 0.7879\n","epoch: 50\n","Training Accuracy: 99.9325% Training Loss: 0.0058\n","Validation Accuracy: 75.1515% Validation Loss: 0.8509\n","epoch: 51\n","Training Accuracy: 100.0000% Training Loss: 0.0046\n","Validation Accuracy: 77.5758% Validation Loss: 0.9390\n","epoch: 52\n","Training Accuracy: 99.8650% Training Loss: 0.0058\n","Validation Accuracy: 77.5758% Validation Loss: 0.7716\n","epoch: 53\n","Training Accuracy: 100.0000% Training Loss: 0.0040\n","Validation Accuracy: 75.1515% Validation Loss: 0.7863\n","epoch: 54\n","Training Accuracy: 100.0000% Training Loss: 0.0040\n","Validation Accuracy: 75.7576% Validation Loss: 0.7497\n","epoch: 55\n","Training Accuracy: 100.0000% Training Loss: 0.0039\n","Validation Accuracy: 78.1818% Validation Loss: 0.8159\n","epoch: 56\n","Training Accuracy: 99.8650% Training Loss: 0.0072\n","Validation Accuracy: 76.3636% Validation Loss: 0.7694\n","epoch: 57\n","Training Accuracy: 100.0000% Training Loss: 0.0053\n","Validation Accuracy: 76.9697% Validation Loss: 0.7444\n","epoch: 58\n","Training Accuracy: 99.9325% Training Loss: 0.0061\n","Validation Accuracy: 76.3636% Validation Loss: 1.0147\n","epoch: 59\n","Training Accuracy: 100.0000% Training Loss: 0.0047\n","Validation Accuracy: 75.1515% Validation Loss: 0.7238\n","epoch: 60\n","Training Accuracy: 100.0000% Training Loss: 0.0048\n","Validation Accuracy: 75.1515% Validation Loss: 0.7739\n","epoch: 61\n","Training Accuracy: 99.8650% Training Loss: 0.0115\n","Validation Accuracy: 74.5455% Validation Loss: 1.0088\n","epoch: 62\n","Training Accuracy: 99.8650% Training Loss: 0.0057\n","Validation Accuracy: 78.1818% Validation Loss: 0.7097\n","epoch: 63\n","Training Accuracy: 99.8650% Training Loss: 0.0085\n","Validation Accuracy: 73.9394% Validation Loss: 0.7324\n","epoch: 64\n","Training Accuracy: 100.0000% Training Loss: 0.0050\n","Validation Accuracy: 78.1818% Validation Loss: 0.7969\n","epoch: 65\n","Training Accuracy: 99.8650% Training Loss: 0.0090\n","Validation Accuracy: 77.5758% Validation Loss: 0.7136\n","epoch: 66\n","Training Accuracy: 100.0000% Training Loss: 0.0032\n","Validation Accuracy: 76.3636% Validation Loss: 0.9393\n","epoch: 67\n","Training Accuracy: 99.8650% Training Loss: 0.0228\n","Validation Accuracy: 76.3636% Validation Loss: 0.7464\n","epoch: 68\n","Training Accuracy: 100.0000% Training Loss: 0.0062\n","Validation Accuracy: 78.1818% Validation Loss: 0.8835\n","epoch: 69\n","Training Accuracy: 100.0000% Training Loss: 0.0034\n","Validation Accuracy: 78.1818% Validation Loss: 0.7843\n","epoch: 70\n","Training Accuracy: 100.0000% Training Loss: 0.0043\n","Validation Accuracy: 75.7576% Validation Loss: 0.8514\n","epoch: 71\n","Training Accuracy: 100.0000% Training Loss: 0.0034\n","Validation Accuracy: 77.5758% Validation Loss: 0.7671\n","epoch: 72\n","Training Accuracy: 99.8650% Training Loss: 0.0073\n","Validation Accuracy: 74.5455% Validation Loss: 0.8244\n","epoch: 73\n","Training Accuracy: 99.9325% Training Loss: 0.0047\n","Validation Accuracy: 77.5758% Validation Loss: 0.8944\n","epoch: 74\n","Training Accuracy: 100.0000% Training Loss: 0.0043\n","Validation Accuracy: 76.3636% Validation Loss: 0.8137\n","epoch: 75\n","Training Accuracy: 99.9325% Training Loss: 0.0047\n","Validation Accuracy: 75.7576% Validation Loss: 0.7017\n","epoch: 76\n","Training Accuracy: 100.0000% Training Loss: 0.0046\n","Validation Accuracy: 75.7576% Validation Loss: 1.0193\n","epoch: 77\n","Training Accuracy: 100.0000% Training Loss: 0.0032\n","Validation Accuracy: 78.7879% Validation Loss: 0.8307\n","epoch: 78\n","Training Accuracy: 100.0000% Training Loss: 0.0056\n","Validation Accuracy: 78.1818% Validation Loss: 0.9674\n","epoch: 79\n","Training Accuracy: 100.0000% Training Loss: 0.0043\n","Validation Accuracy: 75.7576% Validation Loss: 0.9052\n","epoch: 80\n","Training Accuracy: 99.9325% Training Loss: 0.0057\n","Validation Accuracy: 74.5455% Validation Loss: 0.8847\n","epoch: 81\n","Training Accuracy: 100.0000% Training Loss: 0.0047\n","Validation Accuracy: 77.5758% Validation Loss: 0.8126\n","epoch: 82\n","Training Accuracy: 100.0000% Training Loss: 0.0034\n","Validation Accuracy: 76.9697% Validation Loss: 0.8685\n","epoch: 83\n","Training Accuracy: 99.9325% Training Loss: 0.0055\n","Validation Accuracy: 77.5758% Validation Loss: 0.8948\n","epoch: 84\n","Training Accuracy: 100.0000% Training Loss: 0.0030\n","Validation Accuracy: 75.7576% Validation Loss: 0.7306\n","epoch: 85\n","Training Accuracy: 100.0000% Training Loss: 0.0047\n","Validation Accuracy: 78.1818% Validation Loss: 0.9709\n","epoch: 86\n","Training Accuracy: 99.8650% Training Loss: 0.0061\n","Validation Accuracy: 76.3636% Validation Loss: 0.7005\n","epoch: 87\n","Training Accuracy: 99.9325% Training Loss: 0.0075\n","Validation Accuracy: 75.7576% Validation Loss: 0.9392\n","epoch: 88\n","Training Accuracy: 99.8650% Training Loss: 0.0062\n","Validation Accuracy: 77.5758% Validation Loss: 1.0063\n","epoch: 89\n","Training Accuracy: 99.9325% Training Loss: 0.0059\n","Validation Accuracy: 76.3636% Validation Loss: 0.7107\n","epoch: 90\n","Training Accuracy: 100.0000% Training Loss: 0.0043\n","Validation Accuracy: 77.5758% Validation Loss: 1.0443\n","epoch: 91\n","Training Accuracy: 99.9325% Training Loss: 0.0080\n","Validation Accuracy: 73.3333% Validation Loss: 1.1046\n","epoch: 92\n","Training Accuracy: 99.9325% Training Loss: 0.0058\n","Validation Accuracy: 76.9697% Validation Loss: 0.8089\n","epoch: 93\n","Training Accuracy: 99.7299% Training Loss: 0.0130\n","Validation Accuracy: 73.9394% Validation Loss: 0.7118\n","epoch: 94\n","Training Accuracy: 99.9325% Training Loss: 0.0057\n","Validation Accuracy: 76.9697% Validation Loss: 0.7460\n","epoch: 95\n","Training Accuracy: 100.0000% Training Loss: 0.0041\n","Validation Accuracy: 78.1818% Validation Loss: 0.8640\n","epoch: 96\n","Training Accuracy: 100.0000% Training Loss: 0.0050\n","Validation Accuracy: 75.7576% Validation Loss: 0.7134\n","epoch: 97\n","Training Accuracy: 100.0000% Training Loss: 0.0054\n","Validation Accuracy: 73.9394% Validation Loss: 0.8075\n","epoch: 98\n","Training Accuracy: 100.0000% Training Loss: 0.0034\n","Validation Accuracy: 75.7576% Validation Loss: 0.7347\n","epoch: 99\n","Training Accuracy: 99.9325% Training Loss: 0.0061\n","Validation Accuracy: 74.5455% Validation Loss: 0.7320\n","epoch: 100\n","Training Accuracy: 100.0000% Training Loss: 0.0040\n","Validation Accuracy: 75.1515% Validation Loss: 0.7893\n","epoch: 101\n","Training Accuracy: 99.9325% Training Loss: 0.0054\n","Validation Accuracy: 77.5758% Validation Loss: 1.0638\n","epoch: 102\n","Training Accuracy: 99.7974% Training Loss: 0.0190\n","Validation Accuracy: 73.3333% Validation Loss: 0.8494\n","epoch: 103\n","Training Accuracy: 100.0000% Training Loss: 0.0040\n","Validation Accuracy: 77.5758% Validation Loss: 0.8145\n","epoch: 104\n","Training Accuracy: 99.8650% Training Loss: 0.0086\n","Validation Accuracy: 78.1818% Validation Loss: 0.7122\n","epoch: 105\n","Training Accuracy: 100.0000% Training Loss: 0.0042\n","Validation Accuracy: 76.3636% Validation Loss: 0.7771\n","epoch: 106\n","Training Accuracy: 100.0000% Training Loss: 0.0041\n","Validation Accuracy: 77.5758% Validation Loss: 0.8600\n","epoch: 107\n","Training Accuracy: 99.9325% Training Loss: 0.0067\n","Validation Accuracy: 78.1818% Validation Loss: 0.7125\n","epoch: 108\n","Training Accuracy: 100.0000% Training Loss: 0.0046\n","Validation Accuracy: 73.9394% Validation Loss: 0.7112\n","epoch: 109\n","Training Accuracy: 100.0000% Training Loss: 0.0038\n","Validation Accuracy: 77.5758% Validation Loss: 1.2259\n","epoch: 110\n","Training Accuracy: 99.9325% Training Loss: 0.0093\n","Validation Accuracy: 78.1818% Validation Loss: 0.7506\n","epoch: 111\n","Training Accuracy: 99.9325% Training Loss: 0.0074\n","Validation Accuracy: 76.3636% Validation Loss: 0.9202\n","epoch: 112\n","Training Accuracy: 99.9325% Training Loss: 0.0045\n","Validation Accuracy: 76.9697% Validation Loss: 1.0515\n","epoch: 113\n","Training Accuracy: 100.0000% Training Loss: 0.0034\n","Validation Accuracy: 77.5758% Validation Loss: 0.7784\n","epoch: 114\n","Training Accuracy: 100.0000% Training Loss: 0.0048\n","Validation Accuracy: 76.3636% Validation Loss: 1.0369\n","epoch: 115\n","Training Accuracy: 99.9325% Training Loss: 0.0077\n","Validation Accuracy: 73.9394% Validation Loss: 1.0807\n","epoch: 116\n","Training Accuracy: 99.9325% Training Loss: 0.0080\n","Validation Accuracy: 77.5758% Validation Loss: 1.0777\n","epoch: 117\n","Training Accuracy: 99.8650% Training Loss: 0.0134\n","Validation Accuracy: 75.1515% Validation Loss: 0.7771\n","epoch: 118\n","Training Accuracy: 100.0000% Training Loss: 0.0037\n","Validation Accuracy: 76.3636% Validation Loss: 0.7286\n","epoch: 119\n","Training Accuracy: 99.9325% Training Loss: 0.0039\n","Validation Accuracy: 78.1818% Validation Loss: 0.8217\n","epoch: 120\n","Training Accuracy: 100.0000% Training Loss: 0.0060\n","Validation Accuracy: 75.1515% Validation Loss: 0.8629\n","epoch: 121\n","Training Accuracy: 100.0000% Training Loss: 0.0039\n","Validation Accuracy: 77.5758% Validation Loss: 0.7221\n","epoch: 122\n","Training Accuracy: 100.0000% Training Loss: 0.0028\n","Validation Accuracy: 77.5758% Validation Loss: 0.7180\n","epoch: 123\n","Training Accuracy: 99.8650% Training Loss: 0.0060\n","Validation Accuracy: 77.5758% Validation Loss: 0.7676\n","epoch: 124\n","Training Accuracy: 100.0000% Training Loss: 0.0051\n","Validation Accuracy: 78.1818% Validation Loss: 0.9114\n","epoch: 125\n","Training Accuracy: 100.0000% Training Loss: 0.0033\n","Validation Accuracy: 76.3636% Validation Loss: 0.7270\n","epoch: 126\n","Training Accuracy: 100.0000% Training Loss: 0.0035\n","Validation Accuracy: 77.5758% Validation Loss: 0.9327\n","epoch: 127\n","Training Accuracy: 99.9325% Training Loss: 0.0160\n","Validation Accuracy: 75.1515% Validation Loss: 0.7312\n","epoch: 128\n","Training Accuracy: 100.0000% Training Loss: 0.0054\n","Validation Accuracy: 77.5758% Validation Loss: 0.8612\n","epoch: 129\n","Training Accuracy: 100.0000% Training Loss: 0.0043\n","Validation Accuracy: 77.5758% Validation Loss: 0.9594\n","epoch: 130\n","Training Accuracy: 99.9325% Training Loss: 0.0048\n","Validation Accuracy: 77.5758% Validation Loss: 0.7122\n","epoch: 131\n","Training Accuracy: 100.0000% Training Loss: 0.0040\n","Validation Accuracy: 77.5758% Validation Loss: 1.0453\n","epoch: 132\n","Training Accuracy: 100.0000% Training Loss: 0.0048\n","Validation Accuracy: 75.7576% Validation Loss: 0.7253\n","epoch: 133\n","Training Accuracy: 99.9325% Training Loss: 0.0036\n","Validation Accuracy: 75.7576% Validation Loss: 0.9132\n","epoch: 134\n","Training Accuracy: 100.0000% Training Loss: 0.0041\n","Validation Accuracy: 76.9697% Validation Loss: 0.7968\n","epoch: 135\n","Training Accuracy: 99.9325% Training Loss: 0.0149\n","Validation Accuracy: 75.1515% Validation Loss: 0.8175\n","epoch: 136\n","Training Accuracy: 100.0000% Training Loss: 0.0036\n","Validation Accuracy: 74.5455% Validation Loss: 1.1038\n","epoch: 137\n","Training Accuracy: 99.9325% Training Loss: 0.0043\n","Validation Accuracy: 77.5758% Validation Loss: 0.7388\n","epoch: 138\n","Training Accuracy: 100.0000% Training Loss: 0.0039\n","Validation Accuracy: 76.3636% Validation Loss: 0.9535\n","epoch: 139\n","Training Accuracy: 99.9325% Training Loss: 0.0055\n","Validation Accuracy: 76.9697% Validation Loss: 0.9338\n","epoch: 140\n","Training Accuracy: 99.7299% Training Loss: 0.0358\n","Validation Accuracy: 74.5455% Validation Loss: 0.7236\n","epoch: 141\n","Training Accuracy: 100.0000% Training Loss: 0.0033\n","Validation Accuracy: 76.9697% Validation Loss: 0.7002\n","epoch: 142\n","Training Accuracy: 100.0000% Training Loss: 0.0038\n","Validation Accuracy: 78.1818% Validation Loss: 0.9074\n","epoch: 143\n","Training Accuracy: 99.8650% Training Loss: 0.0067\n","Validation Accuracy: 75.1515% Validation Loss: 0.7555\n","epoch: 144\n","Training Accuracy: 100.0000% Training Loss: 0.0057\n","Validation Accuracy: 77.5758% Validation Loss: 0.9374\n","epoch: 145\n","Training Accuracy: 99.9325% Training Loss: 0.0049\n","Validation Accuracy: 77.5758% Validation Loss: 0.7935\n","epoch: 146\n","Training Accuracy: 99.8650% Training Loss: 0.0108\n","Validation Accuracy: 73.9394% Validation Loss: 0.7195\n","epoch: 147\n","Training Accuracy: 99.7299% Training Loss: 0.0083\n","Validation Accuracy: 76.9697% Validation Loss: 1.0426\n","epoch: 148\n","Training Accuracy: 100.0000% Training Loss: 0.0046\n","Validation Accuracy: 76.3636% Validation Loss: 0.7158\n","epoch: 149\n","Training Accuracy: 100.0000% Training Loss: 0.0055\n","Validation Accuracy: 79.3939% Validation Loss: 0.7703\n","epoch: 150\n","Training Accuracy: 99.9325% Training Loss: 0.0059\n","Validation Accuracy: 77.5758% Validation Loss: 0.7604\n","epoch: 151\n","Training Accuracy: 100.0000% Training Loss: 0.0046\n","Validation Accuracy: 75.7576% Validation Loss: 0.7675\n","epoch: 152\n","Training Accuracy: 100.0000% Training Loss: 0.0045\n","Validation Accuracy: 76.3636% Validation Loss: 0.9394\n","epoch: 153\n","Training Accuracy: 99.9325% Training Loss: 0.0052\n","Validation Accuracy: 76.9697% Validation Loss: 0.7158\n","epoch: 154\n","Training Accuracy: 99.7299% Training Loss: 0.0125\n","Validation Accuracy: 78.1818% Validation Loss: 0.9529\n","epoch: 155\n","Training Accuracy: 100.0000% Training Loss: 0.0067\n","Validation Accuracy: 73.9394% Validation Loss: 0.8588\n","epoch: 156\n","Training Accuracy: 99.9325% Training Loss: 0.0055\n","Validation Accuracy: 78.1818% Validation Loss: 0.8575\n","epoch: 157\n","Training Accuracy: 100.0000% Training Loss: 0.0040\n","Validation Accuracy: 76.3636% Validation Loss: 0.7046\n","epoch: 158\n","Training Accuracy: 99.9325% Training Loss: 0.0049\n","Validation Accuracy: 75.7576% Validation Loss: 0.7235\n","epoch: 159\n","Training Accuracy: 100.0000% Training Loss: 0.0047\n","Validation Accuracy: 76.9697% Validation Loss: 0.9706\n","epoch: 160\n","Training Accuracy: 100.0000% Training Loss: 0.0045\n","Validation Accuracy: 75.7576% Validation Loss: 0.7578\n","epoch: 161\n","Training Accuracy: 99.9325% Training Loss: 0.0047\n","Validation Accuracy: 77.5758% Validation Loss: 0.8256\n","epoch: 162\n","Training Accuracy: 99.9325% Training Loss: 0.0064\n","Validation Accuracy: 74.5455% Validation Loss: 0.7978\n","epoch: 163\n","Training Accuracy: 99.9325% Training Loss: 0.0090\n","Validation Accuracy: 71.5152% Validation Loss: 0.8447\n","epoch: 164\n","Training Accuracy: 99.9325% Training Loss: 0.0045\n","Validation Accuracy: 76.3636% Validation Loss: 0.7899\n","epoch: 165\n","Training Accuracy: 99.9325% Training Loss: 0.0041\n","Validation Accuracy: 77.5758% Validation Loss: 0.7021\n","epoch: 166\n","Training Accuracy: 100.0000% Training Loss: 0.0057\n","Validation Accuracy: 78.1818% Validation Loss: 0.7079\n","epoch: 167\n","Training Accuracy: 100.0000% Training Loss: 0.0063\n","Validation Accuracy: 73.9394% Validation Loss: 0.8140\n","epoch: 168\n","Training Accuracy: 99.9325% Training Loss: 0.0048\n","Validation Accuracy: 76.3636% Validation Loss: 0.7101\n","epoch: 169\n","Training Accuracy: 100.0000% Training Loss: 0.0046\n","Validation Accuracy: 76.3636% Validation Loss: 0.7041\n","epoch: 170\n","Training Accuracy: 100.0000% Training Loss: 0.0046\n","Validation Accuracy: 75.1515% Validation Loss: 0.8421\n","epoch: 171\n","Training Accuracy: 99.9325% Training Loss: 0.0073\n","Validation Accuracy: 77.5758% Validation Loss: 0.7250\n","epoch: 172\n","Training Accuracy: 99.9325% Training Loss: 0.0052\n","Validation Accuracy: 77.5758% Validation Loss: 0.7400\n","epoch: 173\n","Training Accuracy: 99.9325% Training Loss: 0.0052\n","Validation Accuracy: 77.5758% Validation Loss: 0.8501\n","epoch: 174\n","Training Accuracy: 99.8650% Training Loss: 0.0082\n","Validation Accuracy: 76.9697% Validation Loss: 0.9572\n","epoch: 175\n","Training Accuracy: 100.0000% Training Loss: 0.0050\n","Validation Accuracy: 75.7576% Validation Loss: 0.8964\n","epoch: 176\n","Training Accuracy: 99.8650% Training Loss: 0.0092\n","Validation Accuracy: 77.5758% Validation Loss: 0.7960\n","epoch: 177\n","Training Accuracy: 100.0000% Training Loss: 0.0065\n","Validation Accuracy: 75.7576% Validation Loss: 0.7520\n","epoch: 178\n","Training Accuracy: 99.8650% Training Loss: 0.0184\n","Validation Accuracy: 74.5455% Validation Loss: 0.9132\n","epoch: 179\n","Training Accuracy: 100.0000% Training Loss: 0.0052\n","Validation Accuracy: 75.1515% Validation Loss: 0.7431\n","epoch: 180\n","Training Accuracy: 99.9325% Training Loss: 0.0060\n","Validation Accuracy: 75.7576% Validation Loss: 0.7897\n","epoch: 181\n","Training Accuracy: 100.0000% Training Loss: 0.0034\n","Validation Accuracy: 78.1818% Validation Loss: 0.7956\n","epoch: 182\n","Training Accuracy: 99.9325% Training Loss: 0.0062\n","Validation Accuracy: 78.1818% Validation Loss: 0.8891\n","epoch: 183\n","Training Accuracy: 99.8650% Training Loss: 0.0078\n","Validation Accuracy: 75.7576% Validation Loss: 1.0888\n","epoch: 184\n","Training Accuracy: 99.9325% Training Loss: 0.0060\n","Validation Accuracy: 75.1515% Validation Loss: 0.8568\n","epoch: 185\n","Training Accuracy: 99.9325% Training Loss: 0.0049\n","Validation Accuracy: 77.5758% Validation Loss: 0.8036\n","epoch: 186\n","Training Accuracy: 100.0000% Training Loss: 0.0031\n","Validation Accuracy: 77.5758% Validation Loss: 0.8016\n","epoch: 187\n","Training Accuracy: 99.9325% Training Loss: 0.0049\n","Validation Accuracy: 76.3636% Validation Loss: 0.7416\n","epoch: 188\n","Training Accuracy: 99.9325% Training Loss: 0.0040\n","Validation Accuracy: 78.1818% Validation Loss: 0.7547\n","epoch: 189\n","Training Accuracy: 99.9325% Training Loss: 0.0051\n","Validation Accuracy: 75.7576% Validation Loss: 0.8157\n","epoch: 190\n","Training Accuracy: 99.8650% Training Loss: 0.0166\n","Validation Accuracy: 75.1515% Validation Loss: 0.7290\n","epoch: 191\n","Training Accuracy: 99.8650% Training Loss: 0.0097\n","Validation Accuracy: 76.9697% Validation Loss: 1.0378\n","epoch: 192\n","Training Accuracy: 100.0000% Training Loss: 0.0048\n","Validation Accuracy: 77.5758% Validation Loss: 0.8980\n","epoch: 193\n","Training Accuracy: 100.0000% Training Loss: 0.0042\n","Validation Accuracy: 75.7576% Validation Loss: 0.7545\n","epoch: 194\n","Training Accuracy: 100.0000% Training Loss: 0.0048\n","Validation Accuracy: 77.5758% Validation Loss: 0.7296\n","epoch: 195\n","Training Accuracy: 99.9325% Training Loss: 0.0087\n","Validation Accuracy: 78.1818% Validation Loss: 0.8137\n","epoch: 196\n","Training Accuracy: 100.0000% Training Loss: 0.0066\n","Validation Accuracy: 77.5758% Validation Loss: 0.7625\n","epoch: 197\n","Training Accuracy: 100.0000% Training Loss: 0.0034\n","Validation Accuracy: 75.1515% Validation Loss: 0.7985\n","epoch: 198\n","Training Accuracy: 100.0000% Training Loss: 0.0032\n","Validation Accuracy: 76.3636% Validation Loss: 0.7042\n","epoch: 199\n","Training Accuracy: 99.9325% Training Loss: 0.0203\n","Validation Accuracy: 76.9697% Validation Loss: 0.9486\n","epoch: 200\n","Training Accuracy: 100.0000% Training Loss: 0.0046\n","Validation Accuracy: 75.7576% Validation Loss: 0.8634\n"]}],"source":["####################  implement your optimizer ###################################\n","## you can use any training methods if you want (ex:lr decay, weight decay.....)\n","learning_rate = 1e-4\n","epochs = 200\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n","criterion = nn.CrossEntropyLoss()\n","\n","# start training\n","model.to(device=device)\n","acc_best = 0.0\n","\n","print('--------------start training--------------')\n","for epoch in range(1, epochs+1):\n","\n","    print('epoch:', epoch)\n","    train(model, criterion, optimizer)\n","    accuracy = valid(model, criterion, scheduler)\n","\n","    if accuracy > acc_best:\n","        acc_best = accuracy\n","        print(\"model saved\")\n","        # save the model\n","        torch.save(model, \"model_rn18.pth\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.17"},"colab":{"provenance":[],"gpuType":"V100"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}